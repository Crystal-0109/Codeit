{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parkf\\AppData\\Local\\Temp\\ipykernel_3672\\3203518255.py:8: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\parkf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\parkf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\parkf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\parkf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\parkf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\parkf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\parkf\\AppData\\Roaming\\nltk_data...\n",
      "C:\\Users\\parkf\\AppData\\Local\\Temp\\ipykernel_3672\\3203518255.py:25: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv('imdb.tsv', delimiter = \"\\\\t\")\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from text import TEXT\n",
    "from preprocess import clean_by_freq\n",
    "from preprocess import clean_by_len\n",
    "from preprocess import clean_by_stopwords\n",
    "from preprocess import stemming_by_porter\n",
    "from preprocess import pos_tagger\n",
    "from preprocess import words_lemmatizer\n",
    "from preprocess import swn_polarity\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv('imdb.tsv', delimiter = \"\\\\t\")\n",
    "\n",
    "# 대소문자 통합\n",
    "df['review'] = df['review'].str.lower()\n",
    "\n",
    "# 문장 토큰화\n",
    "df['sent_tokens'] = df['review'].apply(sent_tokenize)\n",
    "\n",
    "# 품사 태깅\n",
    "df['pos_tagged_tokens'] = df['sent_tokens'].apply(pos_tagger)\n",
    "\n",
    "# 표제어 추출\n",
    "df['lemmatized_tokens'] = df['pos_tagged_tokens'].apply(words_lemmatizer)\n",
    "\n",
    "# 추가 전처리\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "\n",
    "df['cleaned_tokens'] = df['lemmatized_tokens'].apply(lambda x: clean_by_freq(x, 1))\n",
    "df['cleaned_tokens'] = df['cleaned_tokens'].apply(lambda x: clean_by_len(x, 2))\n",
    "df['cleaned_tokens'] = df['cleaned_tokens'].apply(lambda x: clean_by_stopwords(x, stopwords_set))\n",
    "\n",
    "# SentiWordnet 감성 분석\n",
    "df['swn_sentiment'] = df['pos_tagged_tokens'].apply(swn_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "text1 = \"This is a great movie!\"\n",
    "text2 = \"This is a terrible movie!\"\n",
    "text3 = \"This movie was just okay.\"\n",
    "\n",
    "# VADER 감성 분석\n",
    "senti_scores_text1 = senti_analyzer.polarity_scores(text1)\n",
    "senti_scores_text2 = senti_analyzer.polarity_scores(text2)\n",
    "senti_scores_text3 = senti_analyzer.polarity_scores(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.406, 'pos': 0.594, 'compound': 0.6588}\n",
      "{'neg': 0.531, 'neu': 0.469, 'pos': 0.0, 'compound': -0.5255}\n",
      "{'neg': 0.0, 'neu': 0.678, 'pos': 0.322, 'compound': 0.2263}\n"
     ]
    }
   ],
   "source": [
    "# 결과 확인\n",
    "print(senti_scores_text1)\n",
    "print(senti_scores_text2)\n",
    "print(senti_scores_text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"watching time chasers, it obvious that it was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i saw this film about 20 years ago and remembe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>minor spoilers in new york, joan barnard (elvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i went to see this film with a great deal of e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"yes, i agree with everyone on this site this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"jennifer ehle was sparkling in \\\"\"pride and p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>amy poehler is a terrific comedian on saturday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"a plane carrying employees of a large biotech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a well made, gritty science fiction movie, it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"incredibly dumb and utterly predictable story...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  \"watching time chasers, it obvious that it was...\n",
       "1  i saw this film about 20 years ago and remembe...\n",
       "2  minor spoilers in new york, joan barnard (elvi...\n",
       "3  i went to see this film with a great deal of e...\n",
       "4  \"yes, i agree with everyone on this site this ...\n",
       "5  \"jennifer ehle was sparkling in \\\"\"pride and p...\n",
       "6  amy poehler is a terrific comedian on saturday...\n",
       "7  \"a plane carrying employees of a large biotech...\n",
       "8  a well made, gritty science fiction movie, it ...\n",
       "9  \"incredibly dumb and utterly predictable story..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SentiWordNet 감성 분석 레슨에서 진행했던 데이터로 VADER 감성 분석\n",
    "df[['review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감성 분석 함수\n",
    "def vader_sentiment(text):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    # VADER 감성 분석\n",
    "    senti_score = analyzer.polarity_scores(text)['compound']\n",
    "    \n",
    "    return senti_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>swn_sentiment</th>\n",
       "      <th>vader_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"watching time chasers, it obvious that it was...</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.9095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i saw this film about 20 years ago and remembe...</td>\n",
       "      <td>-1.500</td>\n",
       "      <td>-0.9694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>minor spoilers in new york, joan barnard (elvi...</td>\n",
       "      <td>-2.250</td>\n",
       "      <td>-0.2794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i went to see this film with a great deal of e...</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.9707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"yes, i agree with everyone on this site this ...</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.8049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"jennifer ehle was sparkling in \\\"\"pride and p...</td>\n",
       "      <td>6.750</td>\n",
       "      <td>0.9494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>amy poehler is a terrific comedian on saturday...</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.8473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"a plane carrying employees of a large biotech...</td>\n",
       "      <td>8.750</td>\n",
       "      <td>0.9885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a well made, gritty science fiction movie, it ...</td>\n",
       "      <td>4.500</td>\n",
       "      <td>0.9887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"incredibly dumb and utterly predictable story...</td>\n",
       "      <td>-1.125</td>\n",
       "      <td>-0.7375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  swn_sentiment  \\\n",
       "0  \"watching time chasers, it obvious that it was...         -0.375   \n",
       "1  i saw this film about 20 years ago and remembe...         -1.500   \n",
       "2  minor spoilers in new york, joan barnard (elvi...         -2.250   \n",
       "3  i went to see this film with a great deal of e...         -0.500   \n",
       "4  \"yes, i agree with everyone on this site this ...          3.000   \n",
       "5  \"jennifer ehle was sparkling in \\\"\"pride and p...          6.750   \n",
       "6  amy poehler is a terrific comedian on saturday...          0.750   \n",
       "7  \"a plane carrying employees of a large biotech...          8.750   \n",
       "8  a well made, gritty science fiction movie, it ...          4.500   \n",
       "9  \"incredibly dumb and utterly predictable story...         -1.125   \n",
       "\n",
       "   vader_sentiment  \n",
       "0          -0.9095  \n",
       "1          -0.9694  \n",
       "2          -0.2794  \n",
       "3          -0.9707  \n",
       "4           0.8049  \n",
       "5           0.9494  \n",
       "6           0.8473  \n",
       "7           0.9885  \n",
       "8           0.9887  \n",
       "9          -0.7375  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vader_sentiment'] = df['review'].apply(vader_sentiment)\n",
    "\n",
    "df[['review', 'swn_sentiment', 'vader_sentiment']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
